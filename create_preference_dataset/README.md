This folder contains files for creating a DPO pipeline. More precise, with these scripts you can create a DPO dataset from the APPS dataset. The procedure is the following:

1) *transfer_create_sample_calls.py*: For every problem that is call-based and has at least one sample input in APPS, the problem is transferred into the data/APPS/preference folder. For non-class tasks, one file with a sample solution and an another file with a sample call is saved. This file will later be used for type annotation. Method heads in class task methods are already annotated, so here the method head from starter_code.py is inserted into a sample solution and saved to a file in the preference directory.

2) *annotate.py*: TO BE CHANGED! (run it directly in python file or smth) write annotate.sh script for running monkeytype for annotation of non-class based tasks.Run the script to annotate.

3) *run_crosshair.py*: Run crosshair on each code to generate inputs. If there is an error, delete the folder

4) *create_outputs_for_crosshair_preference.py*: For each input generated by crosshair, run the program with these parameters and save the output. If the code throws an error, do not do anything

5) *bring_data_into_preference.py*: TO BE CHANGED (do it directly e.g. in 1): copy the question and the starter code 

6) *scripts/generate.sh*: generate codes for DPO tasks using warmed up model

7) *scripts/run_unit_test.sh*: run unit tests over generated codes

8) *create_dpo_dataset.py*: using generated codes and test output, creates the DPO dataset